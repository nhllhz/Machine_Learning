{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Automático 1\n",
    "# IEFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALUMNO: Nahuel Lahoz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Parte - Imputación\n",
    "\n",
    "- Se le da el dataset real correspondiente a un Banco de Japón, *japan_bank_500_conNulos.csv*. En este dataset la variable target es la y, en cuanto a las features las hay numéricas y categóricas.\n",
    "- El banco no nos proveyó de una descripción de qué es cada variable (habitual en estos casos!) .  \n",
    "\n",
    "- El dataset tiene muchos nulos.   \n",
    "\n",
    "- Su primer tarea es imputar algún tipo de valor a los nulos de cada feature. \n",
    "\n",
    "Para ello:  \n",
    "\n",
    "- Divida  hasta Validation Train y Validation Test. Cada división deberá hacerse 80/20 y con semilla 123.\n",
    "\n",
    "- A nivel de Validation probará **distintas formas de imputar los nulos** (por ejemplo imputar media o mediana etc) y las evaluará en un **único modelo**  que será árbol con 4 niveles de profundidad en todos los casos. Tenga en cuenta que las variables categóricas deberán pasar por OneHotEncoder para ser útiles y la misma target posiblemente también. \n",
    "\n",
    "- La estrategia de imputación que le de mejor resultado de Accuracy con el mencionado árbol entrenando en el Validation Train y evaluando en el Validation Test será la forma de imputación elegida para la segunda parte ya que asumiremos que es la mejor para este dataset. \n",
    "\n",
    "En la celda siguiente escriba cuál fue la estrategia de imputación elegida y los valores de Accuracy obtenidos en cada caso. Si le resulta incómodo hacerlo aquí, puede escribir el resumen en Word. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El imputador elegido es el 3. Este tiene la siguientes carcateristicas:\n",
    "* A los missing values numericos les imputa el valor a traves del Knn imputer con vecinos 5.\n",
    "* A los valores categoricos, les asigna la moda\n",
    "* Accuracy: 0.7875\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer #Imputador\n",
    "from sklearn.model_selection import train_test_split #Split df\n",
    "from sklearn.compose import ColumnTransformer #Transformador de columnas\n",
    "from sklearn.preprocessing import OneHotEncoder #Dummy categoricas\n",
    "from sklearn.impute import KNNImputer #Imputador kNn\n",
    "from sklearn.tree import DecisionTreeClassifier #arbol de decision\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score #Metricas\n",
    "from sklearn.preprocessing import MinMaxScaler #Normalizador\n",
    "from sklearn import neighbors #KNN\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression #Regresion logistoca\n",
    "\n",
    "# sólo para que no muestre el Warning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data\\japan_bank_500_conNulos.csv\") #cargo el df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunm Name :  x1\n",
      "Column Contents :  ['b' nan 'a']\n",
      "Colunm Name :  x4\n",
      "Column Contents :  [nan 'y' 'u' 'l']\n",
      "Colunm Name :  x5\n",
      "Column Contents :  ['g' 'p' nan 'gg']\n",
      "Colunm Name :  x6\n",
      "Column Contents :  [nan 'ff' 'c' 'cc' 'm' 'w' 'i' 'aa' 'j' 'e' 'x' 'q' 'd' 'k' 'r']\n",
      "Colunm Name :  x7\n",
      "Column Contents :  ['v' nan 'ff' 'h' 'bb' 'j' 'n' 'z' 'dd' 'o']\n",
      "Colunm Name :  x9\n",
      "Column Contents :  ['f' 't' nan]\n",
      "Colunm Name :  x10\n",
      "Column Contents :  ['f' nan 't']\n",
      "Colunm Name :  x12\n",
      "Column Contents :  ['f' 't' nan]\n",
      "Colunm Name :  x13\n",
      "Column Contents :  [nan 'g' 's' 'p']\n",
      "Colunm Name :  y\n",
      "Column Contents :  ['-' '+']\n"
     ]
    }
   ],
   "source": [
    "#Analisis de cada columna\n",
    "df_obj=df.select_dtypes(object,bool)\n",
    "for (columnName, columnData) in df_obj.iteritems():\n",
    "        print('Colunm Name : ', columnName)\n",
    "        print('Column Contents : ',columnData.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luego de obtener los unique de cada columna categorica, creo estas variables donde guardo su valor\n",
    "#para pasarselo despues al O.H.E\n",
    "\n",
    "v_x1=['b','a']\n",
    "v_x4=[ 'y', 'u', 'l']\n",
    "v_x5=['g', 'p' ,'gg']\n",
    "v_x6=['ff', 'c', 'cc', 'm', 'w' ,'i' ,'aa' ,'j', 'e', 'x', 'q', 'd', 'k', 'r']\n",
    "v_x7=['v' , 'ff' ,'h', 'bb', 'j', 'n' ,'z' ,'dd' ,'o']\n",
    "v_x9=['f' ,'t' ]\n",
    "v_x10=['f' ,'t' ]\n",
    "v_x12=['f' ,'t' ]\n",
    "v_x13=[ 'g', 's' ,'p']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunm Name :  x2\n",
      "Column Contents :  count    295.000000\n",
      "mean      31.311729\n",
      "std       11.501261\n",
      "min       13.750000\n",
      "25%       22.625000\n",
      "50%       28.580000\n",
      "75%       36.960000\n",
      "max       80.250000\n",
      "Name: x2, dtype: float64\n",
      "Colunm Name :  x3\n",
      "Column Contents :  count      317.000000\n",
      "mean      1181.044826\n",
      "std       3456.727099\n",
      "min          0.000000\n",
      "25%          1.710000\n",
      "50%          6.500000\n",
      "75%        165.000000\n",
      "max      25125.000000\n",
      "Name: x3, dtype: float64\n",
      "Colunm Name :  x8\n",
      "Column Contents :  count      311.000000\n",
      "mean       384.783794\n",
      "std       1349.843628\n",
      "min          0.000000\n",
      "25%          0.500000\n",
      "50%          2.540000\n",
      "75%        125.000000\n",
      "max      13875.000000\n",
      "Name: x8, dtype: float64\n",
      "Colunm Name :  x11\n",
      "Column Contents :  count    293.000000\n",
      "mean       2.252560\n",
      "std        3.975658\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        3.000000\n",
      "max       19.000000\n",
      "Name: x11, dtype: float64\n",
      "Colunm Name :  x14\n",
      "Column Contents :  count     289.000000\n",
      "mean      199.532872\n",
      "std       204.514397\n",
      "min         0.000000\n",
      "25%        80.000000\n",
      "50%       160.000000\n",
      "75%       280.000000\n",
      "max      2000.000000\n",
      "Name: x14, dtype: float64\n",
      "Colunm Name :  x15\n",
      "Column Contents :  count      292.000000\n",
      "mean       857.506849\n",
      "std       2719.271870\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          7.000000\n",
      "75%        488.000000\n",
      "max      31285.000000\n",
      "Name: x15, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_num=df.select_dtypes(np.number)\n",
    "for (columnName, columnData) in df_num.iteritems():\n",
    "        print('Colunm Name : ', columnName)\n",
    "        print('Column Contents : ',columnData.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparacion de los datos para split\n",
    "x=df.drop(axis=1, labels='y')   #guardamos las variables para X\n",
    "y=df[['y']]                     #guardamos las variables para y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split en test train \n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=123)\n",
    "\n",
    "#Validations\n",
    "X_val_train,X_val_test,y_val_train,y_val_test=train_test_split(X_train,y_train,test_size=0.20,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONVERTIMOS Y EN VALORES NUMERICOS\n",
    "\n",
    "y_train=y_train['y'].map({'-':0,'+':1})\n",
    "y_train= y_train.to_numpy()\n",
    "\n",
    "y_test=y_test['y'].map({'-':0,'+':1})\n",
    "y_test= y_test.to_numpy()\n",
    "\n",
    "y_val_train=y_val_train['y'].map({'-':0,'+':1})\n",
    "y_val_train= y_val_train.to_numpy()\n",
    "\n",
    "y_val_test=y_val_test['y'].map({'-':0,'+':1})\n",
    "y_val_test= y_val_test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transofrmadores numericos\n",
    "cols_num=X_val_train.select_dtypes(np.number).columns \n",
    "t1=('imputador_num', SimpleImputer(strategy='mean',copy=True), cols_num)\n",
    "t2=('imputador_num', SimpleImputer(strategy='median',copy=True), cols_num)\n",
    "t3=('imputador_num', KNNImputer(n_neighbors=5,copy=True), cols_num)\n",
    "t4=('imputador_num', KNNImputer(n_neighbors=5, weights='distance',copy=True), cols_num)\n",
    "\n",
    "\n",
    "\n",
    "#Transfromadores categoricos\n",
    "cols_cat=X_val_train.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "t5=('imputador_cat', SimpleImputer(strategy='most_frequent',copy=True), cols_cat) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformador de columnas\n",
    "transformador_columnas1 = ColumnTransformer(transformers=[t1,t5],remainder='passthrough')  \n",
    "transformador_columnas2 = ColumnTransformer(transformers=[t2,t5],remainder='passthrough') \n",
    "transformador_columnas3 = ColumnTransformer(transformers=[t3,t5],remainder='passthrough') \n",
    "transformador_columnas4 = ColumnTransformer(transformers=[t4,t5],remainder='passthrough') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformador 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas1.fit(X_val_train)\n",
    "\n",
    "X_val_Train_Array = transformador_columnas1.transform(X_val_train)\n",
    "X_val_Test_Array = transformador_columnas1.transform(X_val_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_val_train_Transf=pd.DataFrame(X_val_Train_Array, columns=cols_orden) \n",
    "X_val_test_Transf=pd.DataFrame(X_val_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1),copy=True),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_val_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_val_train=transformador_norm_dummy.transform(X_val_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_val_test_Transformado\n",
    "dummy_X_val_test=transformador_norm_dummy.transform(X_val_test_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol imputador1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación modelo Árbol de Decisión en el Imputador 1\n",
      "****************************************************\n",
      "Accuracy: 0.7125\n"
     ]
    }
   ],
   "source": [
    "# Eleccion de imputacion a valores nulos\n",
    "\n",
    "Arbol_P=DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "\n",
    "# Entrenamos el modelo en el validation\n",
    "Arbol_P.fit(dummy_X_val_train, y_val_train) \n",
    "\n",
    "\n",
    "# Pronosticamos los valores de y para los valores del X Val test\n",
    "y_val_pred = Arbol_P.predict(dummy_X_val_test)\n",
    "\n",
    "\n",
    "# Evaluamos en el Val Test\n",
    "ACTree=accuracy_score(y_val_test,y_val_pred)\n",
    "\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"Evaluación modelo Árbol de Decisión en el Imputador 1\")\n",
    "print('****************************************************')     \n",
    "print('Accuracy:', round(ACTree,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas2.fit(X_val_train)\n",
    "\n",
    "X_val_Train_Array = transformador_columnas2.transform(X_val_train)\n",
    "X_val_Test_Array = transformador_columnas2.transform(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_val_train_Transf=pd.DataFrame(X_val_Train_Array, columns=cols_orden) \n",
    "X_val_test_Transf=pd.DataFrame(X_val_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1),copy=True),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_val_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_val_train=transformador_norm_dummy.transform(X_val_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_val_test_Transformado\n",
    "dummy_X_val_test=transformador_norm_dummy.transform(X_val_test_Transf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol Imputador2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación modelo Árbol de Decisión en el Imputador 2\n",
      "****************************************************\n",
      "Accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "# Eleccion de imputacion a valores nulos\n",
    "\n",
    "Arbol_P=DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "\n",
    "# Entrenamos el modelo en el validation\n",
    "Arbol_P.fit(dummy_X_val_train, y_val_train) \n",
    "\n",
    "\n",
    "# Pronosticamos los valores de y para los valores del X Val test\n",
    "y_val_pred = Arbol_P.predict(dummy_X_val_test)\n",
    "\n",
    "\n",
    "# Evaluamos en el Val Test\n",
    "ACTree=accuracy_score(y_val_test,y_val_pred)\n",
    "\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"Evaluación modelo Árbol de Decisión en el Imputador 2\")\n",
    "print('****************************************************')     \n",
    "print('Accuracy:', round(ACTree,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranformador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas3.fit(X_val_train)\n",
    "\n",
    "X_val_Train_Array = transformador_columnas3.transform(X_val_train)\n",
    "X_val_Test_Array = transformador_columnas3.transform(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_val_train_Transf=pd.DataFrame(X_val_Train_Array, columns=cols_orden) \n",
    "X_val_test_Transf=pd.DataFrame(X_val_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1),copy=True),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_val_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_val_train=transformador_norm_dummy.transform(X_val_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_val_test_Transformado\n",
    "dummy_X_val_test=transformador_norm_dummy.transform(X_val_test_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol imputador3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación modelo Árbol de Decisión en el Imputador 3\n",
      "****************************************************\n",
      "Accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "# Eleccion de imputacion a valores nulos\n",
    "\n",
    "Arbol_P=DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "\n",
    "# Entrenamos el modelo en el validation\n",
    "Arbol_P.fit(dummy_X_val_train, y_val_train) \n",
    "\n",
    "\n",
    "# Pronosticamos los valores de y para los valores del X Val test\n",
    "y_val_pred = Arbol_P.predict(dummy_X_val_test)\n",
    "\n",
    "\n",
    "# Evaluamos en el Val Test\n",
    "ACTree=accuracy_score(y_val_test,y_val_pred)\n",
    "\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"Evaluación modelo Árbol de Decisión en el Imputador 3\")\n",
    "print('****************************************************')     \n",
    "print('Accuracy:', round(ACTree,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformador 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas4.fit(X_val_train)\n",
    "\n",
    "X_val_Train_Array = transformador_columnas4.transform(X_val_train)\n",
    "X_val_Test_Array = transformador_columnas4.transform(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_val_train_Transf=pd.DataFrame(X_val_Train_Array, columns=cols_orden) \n",
    "X_val_test_Transf=pd.DataFrame(X_val_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1),copy=True),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_val_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_val_train=transformador_norm_dummy.transform(X_val_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_val_test_Transformado\n",
    "dummy_X_val_test=transformador_norm_dummy.transform(X_val_test_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol Imputador4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación modelo Árbol de Decisión en el Imputador 4\n",
      "****************************************************\n",
      "Accuracy: 0.7125\n"
     ]
    }
   ],
   "source": [
    "# Eleccion de imputacion a valores nulos\n",
    "\n",
    "Arbol_P=DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "\n",
    "# Entrenamos el modelo en el validation\n",
    "Arbol_P.fit(dummy_X_val_train, y_val_train) \n",
    "\n",
    "\n",
    "# Pronosticamos los valores de y para los valores del X Val test\n",
    "y_val_pred = Arbol_P.predict(dummy_X_val_test)\n",
    "\n",
    "\n",
    "# Evaluamos en el Val Test\n",
    "ACTree=accuracy_score(y_val_test,y_val_pred)\n",
    "\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"Evaluación modelo Árbol de Decisión en el Imputador 4\")\n",
    "print('****************************************************')     \n",
    "print('Accuracy:', round(ACTree,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Parte:  \n",
    "\n",
    "Una vez decidido cómo imputará deberá **elegir el modelo e hiperparámetros** que mejor sirve para pronosticar los valores del target.   \n",
    "- Tenga en cuenta que como hará selección de modelo e hiperparámetros deberá compararlos en el Validation.    \n",
    "\n",
    "- Una vez elegido el mejor modelo, deberá indicar cuál es la Accuracy Esperada cuando el modelo se use con nuevas observaciones. \n",
    "\n",
    " En la celda siguiente indique cuál fue:  \n",
    " \n",
    " - modelo elegido:  Arbol de Decisión\n",
    " - hiperparámetros: Profundidad= 4 \n",
    " - Accuracy Esperada: 0.7875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputacion de los valores con parametros seleccionados\n",
    "\n",
    "A esta altura el df ya esta cargado, dividido en x e y y en train-test.\n",
    "Sin embargo las imputaciones y transformaciones no se aplicaron al df por  el copy=True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transofrmadores numericos\n",
    "cols_num=X_val_train.select_dtypes(np.number).columns \n",
    "t3=('imputador_num', KNNImputer(n_neighbors=5), cols_num)\n",
    "\n",
    "#Transfromadores categoricos\n",
    "cols_cat=X_val_train.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "t5=('imputador_cat', SimpleImputer(strategy='most_frequent'), cols_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador_columnas3 = ColumnTransformer(transformers=[t3,t5],remainder='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas3.fit(X_val_train)\n",
    "\n",
    "X_val_Train_Array = transformador_columnas3.transform(X_val_train)\n",
    "X_val_Test_Array = transformador_columnas3.transform(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_val_train_Transf=pd.DataFrame(X_val_Train_Array, columns=cols_orden) \n",
    "X_val_test_Transf=pd.DataFrame(X_val_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1)),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_val_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_val_train=transformador_norm_dummy.transform(X_val_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_val_test_Transformado\n",
    "dummy_X_val_test=transformador_norm_dummy.transform(X_val_test_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol con diferentes profundidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Arbol de decision de profundidad 1 : 0.7625\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 2 : 0.7875\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 3 : 0.775\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 4 : 0.7875\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 5 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 6 : 0.675\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 7 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 8 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 9 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 10 : 0.7\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 11 : 0.6375\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 12 : 0.65\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 13 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de Arbol de decision de profundidad 14 : 0.725\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "for profundidad in range(1,15):\n",
    "    arbol=DecisionTreeClassifier(max_depth=profundidad, random_state=123)\n",
    "    arbol.fit(dummy_X_val_train,y_val_train)\n",
    "    y_val_pred=arbol.predict(dummy_X_val_test)\n",
    "    ACTree=accuracy_score(y_val_test,y_val_pred)\n",
    "    print(\"Accuracy de Arbol de decision de profundidad\", profundidad,\":\", ACTree)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn con uniform y distancia Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.6375\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.6375\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.625\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.65\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.65\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "#Modelo con peso uniforme\n",
    "\n",
    "for n in range (1,15):\n",
    "    Ku_mod=neighbors.KNeighborsClassifier(n_neighbors=n, weights='uniform',metric='minkowski',p=1)\n",
    "    Ku_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    yval_predK=Ku_mod.predict(dummy_X_val_test)    \n",
    "    ACkNn=accuracy_score(y_val_test,yval_predK)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkNn)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn con uniform y distancia Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.6625\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "for n in range (1,15):\n",
    "    Ku_mod=neighbors.KNeighborsClassifier(n_neighbors=n, weights='uniform',metric='minkowski',p=2)\n",
    "    Ku_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    yval_predK=Ku_mod.predict(dummy_X_val_test)    \n",
    "    ACkNn=accuracy_score(y_val_test,yval_predK)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkNn)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn con uniform y distancia Minkowski =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.7375\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.75\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.6625\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "for n in range (1,15):\n",
    "    Ku_mod=neighbors.KNeighborsClassifier(n_neighbors=n, weights='uniform',metric='minkowski',p=4)\n",
    "    Ku_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    yval_predK=Ku_mod.predict(dummy_X_val_test)    \n",
    "    ACkNn=accuracy_score(y_val_test,yval_predK)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkNn)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn distance, con manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.6625\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.7\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for n in range (1,15):\n",
    "    Kd_mod=neighbors.KNeighborsClassifier(n_neighbors=n,weights='distance',metric='minkowski',p=1 )\n",
    "    Kd_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    y_val_predD=Kd_mod.predict(dummy_X_val_test)\n",
    "    ACkd=accuracy_score(y_val_test,y_val_predD)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkd)\n",
    "    print('****************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn distance, con euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.7\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.6875\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n in range (1,15):\n",
    "    Kd_mod=neighbors.KNeighborsClassifier(n_neighbors=n,weights='distance',metric='minkowski',p=2 )\n",
    "    Kd_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    y_val_predD=Kd_mod.predict(dummy_X_val_test)\n",
    "    ACkd=accuracy_score(y_val_test,y_val_predD)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkd)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNn distance, con Minkowski=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de KnN con vecinos 1 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 2 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 3 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 4 : 0.7375\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 5 : 0.75\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 6 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 7 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 8 : 0.725\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 9 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 10 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 11 : 0.675\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 12 : 0.7125\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 13 : 0.6875\n",
      "****************************************************\n",
      "Accuracy de KnN con vecinos 14 : 0.7\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n in range (1,15):\n",
    "    Kd_mod=neighbors.KNeighborsClassifier(n_neighbors=n,weights='distance',metric='minkowski',p=4 )\n",
    "    Kd_mod.fit(dummy_X_val_train,y_val_train)\n",
    "    y_val_predD=Kd_mod.predict(dummy_X_val_test)\n",
    "    ACkd=accuracy_score(y_val_test,y_val_predD)\n",
    "    print(\"Accuracy de KnN con vecinos\", n ,\":\", ACkd)\n",
    "    print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=LogisticRegression(penalty='none', random_state=123,multi_class='ovr')\n",
    "modelo.fit(dummy_X_val_train,y_val_train)\n",
    "probas=modelo.predict_proba(dummy_X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy de Regresion Logistica con umbral: 0.54 es de: 0.75\n"
     ]
    }
   ],
   "source": [
    "umbral_0=0.54 # que pronostique 0 si la probabilidad es mayor que 0.54\n",
    "y_pred_umbral=[]\n",
    "\n",
    "for i in np.arange(0,probas.shape[0]):\n",
    "    if probas[i][0]>umbral_0:\n",
    "        y_pred_agregar=0\n",
    "    else:\n",
    "        y_pred_agregar=1\n",
    "    \n",
    "    y_pred_umbral.append(y_pred_agregar)\n",
    "    \n",
    "ACC_umbral=accuracy_score(y_val_test,y_pred_umbral)\n",
    "print(\"El accuracy de Regresion Logistica con umbral:\",umbral_0, \"es de:\" ,ACC_umbral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno en el train, testeo en el test\n",
    "#Primero preparo los datos\n",
    "\n",
    "\n",
    "#Transofrmadores numericos\n",
    "cols_num=X_train.select_dtypes(np.number).columns \n",
    "t3=('imputador_num', KNNImputer(n_neighbors=5), cols_num)\n",
    "\n",
    "#Transfromadores categoricos\n",
    "cols_cat=X_train.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "t5=('imputador_cat', SimpleImputer(strategy='most_frequent'), cols_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador_columnas3 = ColumnTransformer(transformers=[t3,t5],remainder='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos con el Validation Train:\n",
    "transformador_columnas3.fit(X_train)\n",
    "\n",
    "X_Train_Array = transformador_columnas3.transform(X_train)\n",
    "X_Test_Array = transformador_columnas3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_train_Transf=pd.DataFrame(X_Train_Array, columns=cols_orden) \n",
    "X_test_Transf=pd.DataFrame(X_Test_Array, columns=cols_orden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1)),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_train_Transf)\n",
    "# Lo aplicamos al df\n",
    "dummy_X_train=transformador_norm_dummy.transform(X_train_Transf)\n",
    "\n",
    "\n",
    "# Lo aplicamos a X_test_Transformado\n",
    "dummy_X_test=transformador_norm_dummy.transform(X_test_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Arbol de decision de profundidad 4 : 0.74\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "arbol=DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "arbol.fit(dummy_X_train,y_train)\n",
    "y_pred=arbol.predict(dummy_X_test)\n",
    "ACTree=accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy de Arbol de decision de profundidad\", 4,\":\", ACTree)\n",
    "print('****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercera Parte:   \n",
    "\n",
    "Ahora deberá generar el modelo para Producción.   \n",
    "\n",
    "- En base a lo anterior cree el modelo para producción.  \n",
    "\n",
    "- Empléelo para pronosticar los valores de y para el dataset *japan_bank_190_X_conNulos_.csv*  que tiene 190 observaciones nuevas.    \n",
    "\n",
    "- Debe guardar los pronósticos en un dataFrame de Pandas de una sola columna exportado a formato csv. El nombre de la columna debe ser y_pred. El nombre del Archivo debe ser SuApellido_SuNombre.csv y deberá entregarlo junto con el desarrollo completo del Parcial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno x e y\n",
    "#Primero preparo los datos\n",
    "\n",
    "\n",
    "#Transofrmadores numericos\n",
    "cols_num=x.select_dtypes(np.number).columns \n",
    "t3=('imputador_num', KNNImputer(n_neighbors=5), cols_num)\n",
    "\n",
    "#Transfromadores categoricos\n",
    "cols_cat=x.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "t5=('imputador_cat', SimpleImputer(strategy='most_frequent'), cols_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador_columnas3 = ColumnTransformer(transformers=[t3,t5],remainder='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo entrenamos \n",
    "transformador_columnas3.fit(x)\n",
    "\n",
    "X_Array = transformador_columnas3.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los data frame por las columnas\n",
    "\n",
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_Transf=pd.DataFrame(X_Array, columns=cols_orden) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transformador para OneHotEncoder \n",
    "t_dummy=(\"onehot\",OneHotEncoder(categories=[v_x1,v_x4,v_x5,v_x6,v_x7,v_x9,v_x10,v_x12,v_x13] ,\n",
    "                                sparse=False), ['x1','x4','x5','x6','x7','x9','x10','x12','x13'])\n",
    "\n",
    "#Normalizador\n",
    "t_normalizador=(\"normalizador\",MinMaxScaler(feature_range=(0, 1)),cols_num)\n",
    "\n",
    "# Creamos el transformador de columnas\n",
    "transformador_norm_dummy = ColumnTransformer(transformers=[t_dummy,t_normalizador],remainder='passthrough')\n",
    "# Lo entrenamos con fit en df\n",
    "transformador_norm_dummy.fit(X_Transf)\n",
    "# Lo aplicamos al df\n",
    "x_final=transformador_norm_dummy.transform(X_Transf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=123)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREAMOS EL MODELO FINAL!!\n",
    "\n",
    "Arbol_prod= DecisionTreeClassifier(max_depth=4,random_state=123) #CREAMOS EL MODELO FINAL\n",
    "Arbol_prod.fit(x_final, y) #LO ENTRENAMOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= pd.read_csv('data\\japan_bank_190_X_conNulos_.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparacion nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le aplico el transformador de columnas donde completo missing values\n",
    "new_data_Array = transformador_columnas3.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_orden=cols_num.tolist() + cols_cat.tolist()\n",
    "\n",
    "X_Transf=pd.DataFrame(new_data_Array, columns=cols_orden) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplico el O.H.E y normalizacion\n",
    "new_data_final=transformador_norm_dummy.transform(X_Transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred =Arbol_prod.predict(new_data_final)\n",
    "#y_pred\n",
    "y_pred_csv= pd.DataFrame(y_pred,columns=['y_pred'])\n",
    "y_pred_csv.to_csv('Lahoz_Nahuel.csv')\n",
    "#y_pred_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -\n",
       "1      -\n",
       "2      -\n",
       "3      -\n",
       "4      +\n",
       "      ..\n",
       "185    -\n",
       "186    +\n",
       "187    -\n",
       "188    +\n",
       "189    -\n",
       "Name: y, Length: 190, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=pd.read_csv('data/japan_bank_190conNulos_.csv')['y']\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AC=accuracy_score(y_true, y_pred)\n",
    "AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
